{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - Read batches and automatically preprocess the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faucetml.data_reader import get_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2\n",
    "MINIBATCH_SIZE = 128\n",
    "\n",
    "fml = get_client(\n",
    "    datastore=\"bigquery\",\n",
    "    credential_path=\"bq_creds.json\",\n",
    "    table_name=\"gradient-decision.test_titanic.training_table\",\n",
    "    ds=\"2020-01-20\",\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=MINIBATCH_SIZE,\n",
    "    chunk_size=MINIBATCH_SIZE * 5,\n",
    "    table_sample_percent=100,\n",
    "    test_split_percent=20,\n",
    "    skip_small_batches=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:05:45 INFO] Got feature: pclass\n",
      "[17:05:45 INFO] Feature pclass normalization: NormalizationParameters(feature_type='ENUM', boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, mode=3.0, possible_values=[1, 2, 3], quantiles=None, min_value=1.0, max_value=3.0)\n",
      "\n",
      "[17:05:45 INFO] Got feature: sex\n",
      "[17:05:45 INFO] Feature sex normalization: NormalizationParameters(feature_type='BINARY', boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, mode=0.0, possible_values=None, quantiles=None, min_value=0.0, max_value=1.0)\n",
      "\n",
      "[17:05:45 INFO] Got feature: age\n",
      "[17:05:45 INFO] Feature stats: original K2: 283.9540853024901 P: 2.1885366286553843e-62 Boxcox K2: 95.95031514141382 P: 1.4610120524223594e-21\n",
      "[17:05:45 INFO] Feature age normalization: NormalizationParameters(feature_type='CONTINUOUS', boxcox_lambda=None, boxcox_shift=None, mean=29.75308609008789, stddev=13.269103050231934, mode=32.36809158325195, possible_values=None, quantiles=None, min_value=0.41999998688697815, max_value=80.0)\n",
      "\n",
      "[17:05:45 INFO] Got feature: num_siblings_or_spouses\n",
      "[17:05:45 INFO] Feature num_siblings_or_spouses normalization: NormalizationParameters(feature_type='ENUM', boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, mode=0.0, possible_values=[0, 1, 2, 3, 4, 5, 8], quantiles=None, min_value=0.0, max_value=8.0)\n",
      "\n",
      "[17:05:45 INFO] Got feature: num_children_or_parents\n",
      "[17:05:45 INFO] Feature num_children_or_parents normalization: NormalizationParameters(feature_type='ENUM', boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, mode=0.0, possible_values=[0, 1, 2, 3, 4, 5, 6], quantiles=None, min_value=0.0, max_value=6.0)\n",
      "\n",
      "[17:05:45 INFO] Got feature: family_size\n",
      "[17:05:45 INFO] Feature family_size normalization: NormalizationParameters(feature_type='ENUM', boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, mode=1.0, possible_values=[1, 2, 3, 4, 5, 6, 7, 8, 11], quantiles=None, min_value=1.0, max_value=11.0)\n",
      "\n",
      "[17:05:45 INFO] Got feature: fare\n",
      "/Users/edoardo/dev/test_faucet/env/lib/python3.7/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "[17:05:45 INFO] Feature stats: original K2: 8672.081857501504 P: 0.0 Boxcox K2: 800.3858248485978 P: 1.5791610999949136e-174\n",
      "[17:05:45 INFO] Feature fare normalization: NormalizationParameters(feature_type='BOXCOX', boxcox_lambda=0.22501732928266704, boxcox_shift=-0.0, mean=4.240716934204102, stddev=2.2940523624420166, mode=8.050000190734863, possible_values=None, quantiles=None, min_value=0.0, max_value=512.3292236328125)\n",
      "\n",
      "[17:05:45 INFO] Got feature: has_cabin\n",
      "[17:05:45 INFO] Feature has_cabin normalization: NormalizationParameters(feature_type='BINARY', boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, mode=0.0, possible_values=None, quantiles=None, min_value=0.0, max_value=1.0)\n",
      "\n",
      "[17:05:45 INFO] Got feature: title\n",
      "[17:05:45 INFO] Feature title normalization: NormalizationParameters(feature_type='ENUM', boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, mode=7.0, possible_values=[0, 1, 2, 3, 4, 5, 6, 7], quantiles=None, min_value=0.0, max_value=7.0)\n",
      "\n",
      "[17:05:45 INFO] Got feature: embarked\n",
      "[17:05:45 INFO] Feature embarked normalization: NormalizationParameters(feature_type='ENUM', boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, mode=1.0, possible_values=[0, 1, 2, 3], quantiles=None, min_value=0.0, max_value=3.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 - compute metadata about features in table and generate preprocessing specifications\n",
    "# 2 - Create PyTorch net that will apply these preprocessing specifications\n",
    "preproc_specs, preprocessor_net = fml.gen_preprocess_specs_and_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalizationParameters(feature_type='CONTINUOUS', boxcox_lambda=None, boxcox_shift=None, mean=29.75308609008789, stddev=13.269103050231934, mode=32.36809158325195, possible_values=None, quantiles=None, min_value=0.41999998688697815, max_value=80.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example preprocessing specification for feature \"age\"\n",
    "preproc_specs[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:06:18 INFO] Generating temp table with following query:\n",
      "[17:06:18 INFO] select * from `gradient-decision.test_titanic.training_table` where date(_PARTITIONTIME) = '2020-01-20' and MOD(ABS(FARM_FINGERPRINT(cast(hash_on as string))), 1000) / 1000 < 0.8;\n",
      "[17:06:18 INFO] Temp table generated. Took 0.74s.\n",
      "[17:06:18 INFO] Epoch 1 contains 721 rows.\n"
     ]
    }
   ],
   "source": [
    "# call once per epoch\n",
    "fml.prep_for_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:06:35 INFO] Got batch 1/6 for epoch 1/2 (8%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features': tensor([[ 0.0000,  0.0000, -0.3582,  ...,  0.0000,  0.0000,  1.0000],\n",
       "         [ 0.0000,  1.0000, -0.6013,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.1321,  ...,  0.0000,  0.0000,  1.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  1.0000, -0.6013,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -1.7147,  ...,  1.0000,  0.0000,  0.0000],\n",
       "         [ 1.0000,  0.0000,  1.6766,  ...,  0.0000,  0.0000,  1.0000]]),\n",
       " 'labels': {'survived': tensor([[0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          [0.]])},\n",
       " 'batch_num': 1,\n",
       " 'batches_per_epoch': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a batch of training data that is preprocessed\n",
    "fml.get_batch(preprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:07:08 INFO] Got batch 2/6 for epoch 1/2 (17%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features':      pclass  sex       age  num_siblings_or_spouses  num_children_or_parents  \\\n",
       " 128       3    0  32.00000                        0                        0   \n",
       " 129       1    1  48.00000                        1                        0   \n",
       " 130       3    0  40.50000                        0                        2   \n",
       " 131       1    0  34.00000                        0                        0   \n",
       " 132       3    1   2.00000                        3                        2   \n",
       " ..      ...  ...       ...                      ...                      ...   \n",
       " 251       1    0  32.36809                        0                        0   \n",
       " 252       1    0  60.00000                        1                        1   \n",
       " 253       3    0  32.36809                        2                        0   \n",
       " 254       3    0  10.00000                        3                        2   \n",
       " 255       3    0  20.00000                        0                        0   \n",
       " \n",
       "      family_size      fare  has_cabin  title  embarked  \n",
       " 128            1    8.0500          1      7         1  \n",
       " 129            2   39.6000          1      2         2  \n",
       " 130            3   14.5000          0      7         1  \n",
       " 131            1   26.5500          0      7         1  \n",
       " 132            6   27.9000          0      1         1  \n",
       " ..           ...       ...        ...    ...       ...  \n",
       " 251            1  221.7792          1      7         1  \n",
       " 252            3   79.2000          1      7         2  \n",
       " 253            3   21.6792          0      7         2  \n",
       " 254            6   27.9000          0      5         1  \n",
       " 255            1    9.8458          0      7         1  \n",
       " \n",
       " [128 rows x 10 columns], 'labels':      survived\n",
       " 128         1\n",
       " 129         1\n",
       " 130         0\n",
       " 131         1\n",
       " 132         0\n",
       " ..        ...\n",
       " 251         0\n",
       " 252         1\n",
       " 253         0\n",
       " 254         0\n",
       " 255         0\n",
       " \n",
       " [128 rows x 1 columns], 'batch_num': 2, 'batches_per_epoch': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or get a batch of training data that is not preprocessed\n",
    "fml.get_batch(preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalizationParameters(feature_type='ENUM', boxcox_lambda=None, boxcox_shift=0.0, mean=0.0, stddev=1.0, mode=1.0, possible_values=[1, 2, 3, 4, 5, 6, 7, 8, 11], quantiles=None, min_value=1.0, max_value=11.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easily inspect the preprocessing specification for any given feature\n",
    "preproc_specs[\"family_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
