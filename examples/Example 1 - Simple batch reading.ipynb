{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faucetml.data_reader import get_batch_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 - Read mini-batches from bigquery (no feature store or preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes data stored in Bigquery table with schema:\n",
    "\n",
    "| hash_on (NUMERIC or STRING) |       features (STRUCT)       |  labels (STRUCT) |\n",
    "|-----------------------------|-------------------------------|------------------|\n",
    "|        231248228319         | {\"age\": 16, \"ctr\": 0.021, ...} |  {\"clicked\": 0}  |\n",
    "|        913672219001         | {\"age\": 33, \"ctr\": 0.056, ...} |  {\"clicked\": 0}  |\n",    
    "\n",
    "Note: hash_on is used to conduct consistent sampling & traning / test splitting. In BQ simply use \n",
    "something like `select rand() * 100000 as hash_on, ...` to create the hash_on column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2\n",
    "MINIBATCH_SIZE = 128\n",
    "\n",
    "batch_cli = get_batch_reader(\n",
    "    datastore=\"bigquery\",\n",
    "    credential_path=\"bq_creds.json\",\n",
    "    table_name=\"gradient-decision.test_titanic.training_table\",\n",
    "    ds=\"2020-01-20\",\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=MINIBATCH_SIZE,\n",
    "    chunk_size=MINIBATCH_SIZE * 5,\n",
    "    table_sample_percent=100,\n",
    "    test_split_percent=20,\n",
    "    skip_small_batches=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:01:29 INFO] Generating temp table with following query:\n",
      "[14:01:29 INFO] select * from `gradient-decision.test_titanic.training_table` where date(_PARTITIONTIME) = '2020-01-20' and MOD(ABS(FARM_FINGERPRINT(cast(hash_on as string))), 1000) / 1000 < 0.8;\n",
      "[14:01:30 INFO] Temp table generated. Took 0.54s.\n",
      "[14:01:30 INFO] Epoch 1 contains 721 rows.\n"
     ]
    }
   ],
   "source": [
    "# call once per epoch\n",
    "batch_cli.prep_for_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:01:31 INFO] Got batch 1/6 for epoch 1/2 (8%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features_df':      pclass  sex        age  num_siblings_or_spouses  num_children_or_parents  \\\n",
       " 0         3    0  25.000000                        0                        0   \n",
       " 1         3    1  21.773973                        0                        0   \n",
       " 2         1    0  28.000000                        1                        0   \n",
       " 3         3    0   4.574167                        3                        1   \n",
       " 4         3    1   9.000000                        3                        2   \n",
       " ..      ...  ...        ...                      ...                      ...   \n",
       " 123       2    1  32.000000                        0                        0   \n",
       " 124       3    0  48.000000                        0                        0   \n",
       " 125       2    1  21.773973                        0                        0   \n",
       " 126       3    0   7.000000                        4                        1   \n",
       " 127       1    0  52.000000                        1                        1   \n",
       " \n",
       "      family_size     fare  has_cabin  title  embarked  \n",
       " 0              1   7.0500          0      7         1  \n",
       " 1              1   7.7500          0      1         0  \n",
       " 2              2  82.1708          0      7         2  \n",
       " 3              5  25.4667          0      5         1  \n",
       " 4              6  27.9000          0      1         1  \n",
       " ..           ...      ...        ...    ...       ...  \n",
       " 123            1  13.0000          0      6         1  \n",
       " 124            1   7.8542          0      7         1  \n",
       " 125            1  33.0000          0      1         1  \n",
       " 126            6  39.6875          0      5         1  \n",
       " 127            3  79.6500          1      7         1  \n",
       " \n",
       " [128 rows x 10 columns], 'labels_df':      survived\n",
       " 0           0\n",
       " 1           1\n",
       " 2           0\n",
       " 3           0\n",
       " 4           0\n",
       " ..        ...\n",
       " 123         1\n",
       " 124         0\n",
       " 125         1\n",
       " 126         0\n",
       " 127         0\n",
       " \n",
       " [128 rows x 1 columns], 'batch_num': 1, 'batches_per_epoch': 6}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one batch of training data\n",
    "batch_cli.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:01:36 INFO] Generating temp table with following query:\n",
      "[14:01:36 INFO] select * from `gradient-decision.test_titanic.training_table` where date(_PARTITIONTIME) = '2020-01-20' and MOD(ABS(FARM_FINGERPRINT(cast(hash_on as string))), 1000) / 1000 < 0.8;\n",
      "[14:01:36 INFO] Temp table generated. Took 0.5s.\n",
      "[14:01:36 INFO] Epoch 1 contains 721 rows.\n",
      "[14:01:37 INFO] Got batch 1/6 for epoch 1/2 (8%)\n",
      "[14:01:37 INFO] Got batch 2/6 for epoch 1/2 (17%)\n",
      "[14:01:37 INFO] Got batch 3/6 for epoch 1/2 (25%)\n",
      "[14:01:37 INFO] Got batch 4/6 for epoch 1/2 (33%)\n",
      "[14:01:37 INFO] Got batch 5/6 for epoch 1/2 (42%)\n",
      "[14:01:37 INFO] Got batch 6/6 for epoch 1/2 (50%)\n",
      "[14:01:37 INFO] Generating temp table with following query:\n",
      "[14:01:37 INFO] select * from `gradient-decision.test_titanic.training_table` where date(_PARTITIONTIME) = '2020-01-20' and MOD(ABS(FARM_FINGERPRINT(cast(hash_on as string))), 1000) / 1000 between 0.8 and 1.0\n",
      "[14:01:37 INFO] Temp table generated. Took 0.4s.\n",
      "[14:01:37 INFO] **************************************************\n",
      "[14:01:37 INFO] Starting end of epoch evaluation...\n",
      "[14:01:37 INFO] **************************************************\n",
      "[14:01:37 INFO] Eval pass 1 contains 170 rows.\n",
      "[14:01:38 INFO] Got batch 1/2 for epoch 1/2 (50%)\n",
      "[14:01:38 INFO] Got batch 2/2 for epoch 1/2 (50%)\n",
      "[14:01:38 INFO] Generating temp table with following query:\n",
      "[14:01:38 INFO] select * from `gradient-decision.test_titanic.training_table` where date(_PARTITIONTIME) = '2020-01-20' and MOD(ABS(FARM_FINGERPRINT(cast(hash_on as string))), 1000) / 1000 < 0.8;\n",
      "[14:01:38 INFO] Temp table generated. Took 0.0s.\n",
      "[14:01:38 INFO] Epoch 2 contains 721 rows.\n",
      "[14:01:38 INFO] Got batch 1/6 for epoch 2/2 (58%)\n",
      "[14:01:38 INFO] Got batch 2/6 for epoch 2/2 (67%)\n",
      "[14:01:38 INFO] Got batch 3/6 for epoch 2/2 (75%)\n",
      "[14:01:38 INFO] Got batch 4/6 for epoch 2/2 (83%)\n",
      "[14:01:38 INFO] Got batch 5/6 for epoch 2/2 (92%)\n",
      "[14:01:38 INFO] Got batch 6/6 for epoch 2/2 (100%)\n",
      "[14:01:38 INFO] Generating temp table with following query:\n",
      "[14:01:38 INFO] select * from `gradient-decision.test_titanic.training_table` where date(_PARTITIONTIME) = '2020-01-20' and MOD(ABS(FARM_FINGERPRINT(cast(hash_on as string))), 1000) / 1000 between 0.8 and 1.0\n",
      "[14:01:38 INFO] Temp table generated. Took 0.0s.\n",
      "[14:01:38 INFO] **************************************************\n",
      "[14:01:38 INFO] Starting end of epoch evaluation...\n",
      "[14:01:38 INFO] **************************************************\n",
      "[14:01:38 INFO] Eval pass 2 contains 170 rows.\n",
      "[14:01:38 INFO] Got batch 1/2 for epoch 2/2 (50%)\n",
      "[14:01:38 INFO] Got batch 2/2 for epoch 2/2 (100%)\n"
     ]
    }
   ],
   "source": [
    "# or run through the whole data set\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "\n",
    "    # training\n",
    "    batch_cli.prep_for_epoch()\n",
    "    mini_batch = batch_cli.get_batch()\n",
    "    while mini_batch is not None:\n",
    "        mini_batch = batch_cli.get_batch()\n",
    "        # model.train(mini_batch)\n",
    "        \n",
    "    # eval\n",
    "    batch_cli.prep_for_eval()\n",
    "    mini_batch = batch_cli.get_batch(eval=True) \n",
    "    while mini_batch is not None:\n",
    "        mini_batch = batch_cli.get_batch()\n",
    "        # model.eval(mini_batch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
